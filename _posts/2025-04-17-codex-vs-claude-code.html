---
layout: post
title: "Codex vs Claude Code: Comparing OpenAI and Anthropic AI Pair-Programming Tools"
date: 2025-04-17 22:00:00 +0200
tags: [ai-agents, devtools, codex, claude-code, comparison, ai-pair-programming, ai-developer-tools]
description: "I compared OpenAI Codex and Anthropic's Claude Code for AI-driven pair-programming. See performance benchmarks, UX differences, API cost breakdowns, and practical insights."
image: /assets/posts/2025-04-17-codex-vs-claude-code/codex_intro.png
---
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "TechArticle",
  "headline": "Codex vs Claude Code: Comparing OpenAI and Anthropic AI Pair-Programming Tools",
  "description": "I compared OpenAI Codex and Anthropic Claude Code for AI-driven pair-programming. See benchmarks, UX comparisons, API cost, and practical insights.",
  "author": {
    "@type": "Person",
    "name": "Antonio Cascais"
  },
  "datePublished": "2025-04-17",
  "keywords": ["AI pair programming", "OpenAI Codex", "Anthropic Claude", "AI developer tools", "Codex vs Claude comparison", "AI code assistant"]
}
</script>

<blockquote>â€œShip it, break it, blog it.â€ â€” me, probably</blockquote>

<h2>Why Iâ€™m pitting two bots against each other</h2>

<p><strong><a href="https://github.com/openai/codex" target="_blank" rel="noopener noreferrer" title="OpenAI Codex GitHub Repository">Codex</a></strong> (freshâ€‘minted <em>yesterday</em>,Â 2025â€‘04â€‘16) is OpenAIâ€™s new <strong>openâ€‘source</strong> codeâ€‘agent CLI, designed to work exclusively with OpenAI models. Its direct competitor is Anthropic's <strong><a href="https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview" target="_blank" rel="noopener noreferrer" title="Anthropic Claude Code Documentation">Claudeâ€¯Code</a></strong>, a more established, polished, but closed-source rival which utilizes Anthropic's models (available via their API, AWS Bedrock, or Google Vertex AI). For this comparison, I used the default settings: Codex ran on OpenAI's <code>o4-mini</code>, while Claude Code used Anthropic's <code>claude-3-7-sonnet-20250219</code>. While both tools allow selecting different models *within their respective ecosystems* (e.g., switching Codex to <code>gpt-4o</code> or Claude Code to a Haiku variant), they don't cross platforms.</p>

<p>Some friends have been asking me about my experience with these AI pair programming tools, so I dropped both into my
<code>alfredâ€‘aiâ€‘assistant</code> project (a Go Telegram bot that acts as personal assistant using the OpenAI Assistants API) and asked them to:</p>

<ol>
  <li><strong>Read</strong> the repo.</li>
  <li><strong>Pitch</strong> three improvement tickets.</li>
  <li><strong>Write</strong> the ticket files.</li>
  <li><strong>Implement</strong> one of the tickets and let Google <strong>GeminiÂ 2.5Â Pro</strong> review the pullâ€‘requests (thatâ€™ll be PartÂ 2).</li>
</ol>

<p>I timed everything and checked the API bill so you donâ€™t have to. This post details the Codex vs Claude comparison for these initial tasks, running on their respective default models at the time of writing.</p>
<p><i>(For another example of using AI in development, check out my <a href="https://blog.acascais.com/multi-ai-feature/" title="Multi-AI Workflow: How I Shipped an OCR Feature with Gemini + Claude">Multi-AI Workflow post where I used Gemini and Claude together</a>.)</i></p>

<hr />

<h2>Fast TL;DR â€” Numbers <em>and</em> Vibes</h2>

<p>If you just want the scoreboard, here it is. But numbers alone donâ€™t tell the whole story of these AI developer tools, so I sprinkled in a gutâ€‘feel verdict on each row.</p>

<table>
  <thead><tr><th>Bot</th><th>Analysis time</th><th>Ticket time</th><th>API cost</th><th>Overall vibe</th></tr></thead>
  <tbody>
    <tr><td>Codex</td><td>~30â€¯s</td><td>9â€¯s</td><td><strong>$0.28</strong></td><td>Strong dev that you can trust</td></tr>
    <tr><td>Claudeâ€¯Code</td><td>~50â€¯s</td><td>12â€¯s</td><td><strong>$0.4443</strong></td><td>Seasoned senior dev who invoices accordingly</td></tr>
  </tbody>
</table>

<p>Bottom line: ğŸ¤“ <strong>Codex</strong> already behaves like a <em>strong dev you can trust</em>â€”solid suggestions, quick turnaround, less cost per session. ğŸ¤– <strong>Claude</strong> layers on that extra seniorâ€‘engineer polish and slick UX for an extra cost per run, a premium worth paying if you need the deeper guidance from your AI code assistant.</p>

<hr />

<h2>Installing the contenders</h2>

<p>You can install both AI pair programming CLIs via npm:</p>
<pre><code># Codex (Check official repo/docs for latest install method)
npm install -g @openai/codex

# ClaudeÂ Code (Check official repo/docs for latest install method)
npm install -g @anthropic-ai/claude-code
</code></pre>

<p>Both CLIs need an API key. Codex accepts a <code>.env</code> with <code>OPENAI_API_KEY</code>; Claudeâ€¯Code stashes creds in <code>~/.claude.json</code> after an onboarding wizard.</p>

<hr />

<h2>Round 1: Testing OpenAI Codex CLI</h2>

<figure>
  <img src="/assets/posts/2025-04-17-codex-vs-claude-code/codex-01-explain-codebase-prompt.png" alt="OpenAI Codex CLI initial repository analysis prompt" style="max-width:100%;height:auto;">
  <figcaption>OpenAI Codex CLI initial repository analysis prompt</figcaption>
</figure>

<p>I started with the OpenAI Codex CLI. It poked around the repo (<code>ls</code>, <code>head</code>, etc.) and in ~30â€¯s dumped a <em>9â€‘point</em> architectural recap. Snapshot below is truncated, full text lived in the terminal.</p>


<figure>
  <img src="/assets/posts/2025-04-17-codex-vs-claude-code/codex-02-codebase-explanation.png" alt="OpenAI Codex CLI detailed 9-point Go project breakdown" style="max-width:100%;height:auto;">
  <figcaption>Verbose breakdown from Codex</figcaption>
</figure>

<p>The analysis was <em>longâ€‘winded</em> but accurate. I caught myself nodding along while scrolling.</p>

<h3>Asking for improvements using Codex</h3>

<pre><code>if you had to suggest 3 main tickets to improve this codebase, what would you suggest? and why?
</code></pre>

<figure>
  <img src="/assets/posts/2025-04-17-codex-vs-claude-code/codex-03-ask-for-improvements.png" alt="OpenAI Codex CLI ticket suggestions: Persistence, Config, API Client" style="max-width:100%;height:auto;">
  <figcaption>Codex ticket ideas</figcaption>
</figure>

<p>Nine seconds later Codex fired back three tickets that lined up with a couple of my mental TODO list. Not bad for an AI code assistant.</p>

<ol>
  <li><strong>Thread PersistenceÂ & Lifecycle</strong> â€” ditch JSON and embrace an embedded DB.</li>
  <li><strong>Centralized ConfigÂ & Secrets Management</strong> â€” typed <code>Config</code>, validation, goodbye envâ€‘var spaghetti.</li>
  <li><strong>Resilient API ClientÂ & Structured Errorâ€‘Handling</strong> â€” retries and structured logs instead of <code>panic</code>.</li>
</ol>

<p>When asked to turn ideas into files, Codex turned into that colleague who needs you to hit <code>y</code> on every confirmation dialog.</p>

<figure>
  <img src="/assets/posts/2025-04-17-codex-vs-claude-code/codex-04-example-accept-changes.png" alt="Repetitive file creation confirmation prompts in OpenAI Codex CLI" style="max-width:100%;height:auto;">
  <figcaption>Repetitive y/n prompts in Codex</figcaption>
</figure>

<blockquote>Tip: pass <code>--full-auto</code> if you trust it, but I like fingersâ€‘onâ€‘theâ€‘killâ€‘switch.</blockquote>

<figure>
  <img src="/assets/posts/2025-04-17-codex-vs-claude-code/codex-05-tickets-created.png" alt="Folder tree showing three new markdown ticket files created by Codex" style="max-width:100%;height:auto;">
  <figcaption>Tickets created by Codex</figcaption>
</figure>

<p><em>Example ticket excerpt</em> (<a href="/assets/posts/2025-04-17-codex-vs-claude-code/codex_t1_thread_persistence.md" target="_blank">View the full file</a>):</p>

<pre><code># Thread Persistence & Lifecycle Improvements

## Context
Currently the bot keeps its mapping of Telegram users to OpenAI thread IDs in a flat JSON file (`threads.json`). â€¦
</code></pre>


<h4>Codex bill</h4>

<p>OpenAI usage page: <strong>$0.28</strong>.

<hr />

<h2>Round 2: Evaluating Anthropic Claude Code CLI</h2>

<p>I stashed Codex tickets elsewhere so both bots started clean, launched the Anthropic Claude Code CLI and pasted the same typoâ€‘laden prompt (fair test!). Claude took ~50s slower, but that's okay.</p>

<figure>
  <img src="/assets/posts/2025-04-17-codex-vs-claude-code/claude-02-codebase-explanation.png" alt="Anthropic Claude Code CLI brief high-level project summary" style="max-width:100%;height:auto;">
  <figcaption>Terse summary from ClaudeÂ Code</figcaption>
</figure>

<p>The explanation was conciseâ€”almost too conciseâ€”but it nailed the architecture in half a screen.</p>

<h3>Improvement tickets from Claude Code</h3>
<p>Its three picks:</p>
<ol>
  <li><strong>Implement robust userâ€‘thread mapping</strong> with a real database.</li>
  <li><strong>Enhance error handling and recovery</strong> â€” remove <code>log.Panic</code>, add retries & better
      messages.</li>
  <li><strong>Redesign OpenAI functionâ€‘tool system</strong> for pluginâ€‘style extensibility.</li>
</ol>

<figure>
  <img src="/assets/posts/2025-04-17-codex-vs-claude-code/claude-03-ask-for-improvements.png" alt="Anthropic Claude Code CLI ticket suggestions including function tool redesign" style="max-width:100%;height:auto;">
  <figcaption>ClaudeÂ Code ticket suggestions</figcaption>
</figure>

<p>The overlap with Codex was interesting: same first two tickets, but Claude tossed in a bolder refactor (#3) that Iâ€™d been procrastinating.</p>

<p>File creation was much smoother: one select the option to approve all similar commands and the bot silently did its thing. This is a nice UX touch for an AI developer tool.</p>

<figure>
  <img src="/assets/posts/2025-04-17-codex-vs-claude-code/claude-04-example-accept-changes.png" alt="Anthropic Claude Code CLI permission prompt UX with trust option" style="max-width:100%;height:auto;">
  <figcaption>Smarter permission UX in ClaudeÂ Code</figcaption>
</figure>

<h4>Claudeâ€¯Code bill</h4>

<figure>
  <img src="/assets/posts/2025-04-17-codex-vs-claude-code/claude-06-final-cost.png" alt="Anthropic Claude Code CLI /cost command showing session cost $0.4443" style="max-width:100%;height:auto;">
  <figcaption>ClaudeÂ Code session cost snapshot</figcaption>
</figure>

<p>The builtâ€‘in <code>/cost</code> readout is glorious: spend, duration, lines changedâ€”perfect for keeping track of costs when using these AI tools.</p>

<hr />

<h2>Battle notes & takeâ€‘aways: Codex vs Claude Comparison</h2>

<ul>
  <li><strong>Quality vs cost</strong> â€” Claudeâ€™s tickets felt like staffâ€‘eng blueprints; Codexâ€™s looked like solid midâ€‘level JIRA stories. A key difference in this Codex vs Claude comparison.</li>
  <li><strong>UX</strong> â€” Claudeâ€™s oneâ€‘click trust toggle saves sanity. Codexâ€™s y/n loop gets old fast.</li>
  <li><strong>Builtâ€‘in /cost tracking</strong> â€” huge plus for Claude when youâ€™re watching pennies.</li>
  <li><strong>Speed</strong> â€” Codex wins the stopwatch, but the gap is seconds, not minutes.</li>
  <li><strong>Openâ€‘source momentum</strong> â€” Codex will probably levelâ€‘up quickly once GitHub starts filing issues and PRs.</li>
</ul>

<hr />

<h2>Conclusion â€” Which AI Pair Programming Bot Lives in My Terminal?</h2>

<p>After a day of backâ€‘andâ€‘forth comparing these AI developer tools, Iâ€™m keeping <strong>both</strong> in my toolkit:</p>

<ul>
  <li><strong>Codex (OpenAI Codex CLI)</strong> for rapidâ€‘fire tasks where I value speed and cost over polishâ€”think â€œgenerate a quick migrationâ€ or â€œdraft a READMEâ€.</li>
  <li><strong>Claudeâ€¯Code (Anthropic Claude Code)</strong> when I need seniorâ€‘level reasoning, richer diffs, or when the projectâ€™s budget can absorb the extra cost per session for a premium AI code assistant.</li>
</ul>

<p>The real win is optionality: I can start with Codex and, if it stalls, summon Claude for a second opinion without blowing the monthly AI budget. Effective AI pair programming often involves knowing which tool fits the task.</p>

<p>Next up Iâ€™ll let both bots <em>implement</em> one of their own tickets and have GeminiÂ 2.5Â Pro conduct the code
review. Stay tuned for Part 2 of this Codex vs Claude comparison, featuring AI bot coding fireworks.</p>

<hr />

<h3>Time & money recap</h3>

<ul>
  <li><strong>Codex:</strong> 39s wall time, <strong>$0.28</strong></li>
  <li><strong>Claudeâ€¯Code:</strong> 62s wall time, <strong>$0.4443</strong></li>
</ul>

<hr />

<p><strong>Cheap tools, <em>expensive curiosity</em>.</strong><br>
But hey, at least my terminal now has two new colleaguesâ€”one reliable dev, and one seasoned pro who's worth every penny.</p>

<p><em>Built it, broke it, blogged it. Catch you in PartÂ 2 for more AI-powered fireworks (and hopefully fewer confirmation prompts).</em></p>
